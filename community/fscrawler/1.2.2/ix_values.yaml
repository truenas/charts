# FIXME: Update tags once a stable version is released
ocrImage:
  repository: dadoonet/fscrawler
  pullPolicy: IfNotPresent
  tag: 2.10-SNAPSHOT-ocr-es7

noocrImage:
  repository: dadoonet/fscrawler
  pullPolicy: IfNotPresent
  tag: 2.10-SNAPSHOT-noocr

resources:
  limits:
    cpu: 4000m
    memory: 8Gi

fscrawlerConfig:
  imageSelector: ocrImage
  jobName: ''
  restart: false
  loop: -1
  additionalEnvs: []

fscrawlerNetwork:
  hostNetwork: false
  enableRestApiService: false
  restPort: 30084

fscrawlerStorage:
  jobs:
    type: ixVolume
    ixVolumeConfig:
      datasetName: jobs
  additionalStorages: []

notes:
  custom: |
    ## FSCrawler

    {{- $path := (printf "/root/.fscrawler/%s/_settings.yaml (Inside the container)" .Values.fscrawlerConfig.jobName) -}}
    {{- if eq .Values.fscrawlerStorage.jobs.type "hostPath" -}}
      {{- $path = (printf "%s/%s/_settings.yaml" .Values.fscrawlerStorage.jobs.hostPath .Values.fscrawlerConfig.jobName) -}}
    {{- end }}

    You have to manually Edit/Create the job file at the path:

    ```shell
    {{ $path }}
    ```

    Until a valid job file is created, the FSCrawler container be in the Deploying state.
    A stop and start of the container will be required after the job file is created.

    {{- if .Values.fscrawlerNetwork.enableRestApiService }}
    Rest API Service is enabled. You have to include the following configuration in your job file:

    ```yaml

    # Your _settings.yaml file
    name: {{ .Values.fscrawlerConfig.jobName | quote }}
    rest:
      url: http://0.0.0.0:{{ .Values.fscrawlerNetwork.restPort }}/fscrawler
      # Optionally
      # enable_cors: true/false

    # ...other settings of the job file...
    ```
    {{- end }}
